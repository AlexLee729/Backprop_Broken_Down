# Backprop Broken Down
Implements backpropagation manually and a small neural networks library on top of it with a PyTorch-like API. The purpose of the code is to understand how backpropagation works as it is the fundamental algorithm in all modern neural networks and allows them to be trained.

# Visualization
The image below shows the graph of a basic 2D neuron with all the weights and bias. It shows what a neuron will look like after a backwards pass when all the gradients are calculated through chain rule.
![2D Neuron](Neuron.svg)
